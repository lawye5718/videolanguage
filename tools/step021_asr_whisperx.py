import json
import time
import librosa
import numpy as np
import whisperx
import os
from loguru import logger
import torch
from dotenv import load_dotenv
load_dotenv()

whisper_model = None
diarize_model = None

align_model = None
language_code = None
align_metadata = None

def init_whisperx():
    load_whisper_model()
    load_align_model()

def init_diarize():
    load_diarize_model()
    
def load_whisper_model(model_name: str = 'large', download_root = 'models/ASR/whisper', device='auto'):
    if model_name == 'large':
        pretrain_model = os.path.join(download_root,"faster-whisper-large-v3")
        model_name = 'large-v3' if not os.path.isdir(pretrain_model) else pretrain_model
        
    global whisper_model
    if whisper_model is not None:
        return
    if device == 'auto':
        if torch.backends.mps.is_available():
            device = 'mps'
            compute_type = 'float32'  # Mac MPS å¯¹ float16 æ”¯æŒä¸å®Œå–„
        else:
            device = 'cpu'
            compute_type = 'int8'
    logger.info(f'Loading WhisperX model: {model_name}')
    t_start = time.time()
    if device == 'cpu':
        whisper_model = whisperx.load_model(model_name, download_root=download_root, device=device, compute_type=compute_type)
    elif device == 'mps':
        whisper_model = whisperx.load_model(model_name, download_root=download_root, device=device, compute_type=compute_type)
    else:
        whisper_model = whisperx.load_model(model_name, download_root=download_root, device=device)
    t_end = time.time()
    logger.info(f'Loaded WhisperX model: {model_name} in {t_end - t_start:.2f}s')

def load_align_model(language='en', device='auto', model_dir='models/ASR/whisper'):
    global align_model, language_code, align_metadata
    if align_model is not None and language_code == language:
        return
    if device == 'auto':
        if torch.backends.mps.is_available():
            device = 'mps'
        else:
            device = 'cpu'
    language_code = language
    t_start = time.time()
    align_model, align_metadata = whisperx.load_align_model(
        language_code=language_code, device=device, model_dir = model_dir)
    t_end = time.time()
    logger.info(f'Loaded alignment model: {language_code} in {t_end - t_start:.2f}s')
    
def load_diarize_model(device='auto'):
    global diarize_model
    if diarize_model is not None:
        return
    if device == 'auto':
        if torch.backends.mps.is_available():
            device = 'mps'
        else:
            device = 'cpu'
    
    # æ£€æŸ¥HF_TOKEN
    hf_token = os.getenv('HF_TOKEN')
    if not hf_token:
        logger.warning("âš ï¸ æœªåœ¨ .env ä¸­æ£€æµ‹åˆ° HF_TOKENï¼Œè·³è¿‡è¯´è¯äººåˆ†ç¦»ã€‚å¦‚æœéœ€è¦å¤šè§’è‰²é…éŸ³ï¼Œè¯·é…ç½® HF_TOKENã€‚")
        return
    
    t_start = time.time()
    try:
        # æ³¨æ„ï¼šMac MPS åœ¨ Pyannote æŸäº›ç®—å­ä¸Šå¯èƒ½æŠ¥é”™ï¼Œå¦‚æœè¿™é‡Œå´©æºƒï¼Œè¯·å°† device æ”¹ä¸º "cpu"
        diarize_model = whisperx.DiarizationPipeline(use_auth_token=hf_token, device=device)
        t_end = time.time()
        logger.info(f'âœ… Loaded diarization model in {t_end - t_start:.2f}s')
    except Exception as e:
        t_end = time.time()
        logger.warning(f"âš ï¸ è¯´è¯äººåˆ†ç¦»å¤±è´¥ (å¯èƒ½å› ä¸º Mac ç®—å­ä¸å…¼å®¹): {str(e)}")
        logger.info("ğŸ‘‰ å°†å›é€€åˆ°ä¸åŒºåˆ†è¯´è¯äººçš„å•è§’è‰²æ¨¡å¼ã€‚")
        logger.info("ğŸ’¡ å»ºè®®ï¼šå¦‚æœéœ€è¦è¯´è¯äººåˆ†ç¦»åŠŸèƒ½ï¼Œå¯åœ¨ .env ä¸­è®¾ç½® HF_TOKEN å¹¶å°† device æ”¹ä¸º cpu")

def whisperx_transcribe_audio(wav_path, model_name: str = 'large', download_root='models/ASR/whisper', device='auto', batch_size=32, diarization=True,min_speakers=None, max_speakers=None):
    if device == 'auto':
        if torch.backends.mps.is_available():
            device = 'mps'
        else:
            device = 'cpu'
    
    logger.info(f"â–¶ï¸ å¼€å§‹ WhisperX è¯­éŸ³è¯†åˆ« (è®¾å¤‡: {device})...")
    load_whisper_model(model_name, download_root, device)
    rec_result = whisper_model.transcribe(wav_path, batch_size=batch_size)
    
    if rec_result['language'] == 'nn':
        logger.warning(f'No language detected in {wav_path}')
        return False
    
    logger.info("â–¶ï¸ å¼€å§‹æ—¶é—´æˆ³å¯¹é½...")
    load_align_model(rec_result['language'])
    rec_result = whisperx.align(rec_result['segments'], align_model, align_metadata,
                                wav_path, device, return_char_alignments=False)
    
    if diarization:
        logger.info("â–¶ï¸ å¼€å§‹è¯´è¯äººåˆ†ç¦» (Diarization)...")
        load_diarize_model(device)
        if diarize_model:
            try:
                diarize_segments = diarize_model(wav_path,min_speakers=min_speakers, max_speakers=max_speakers)
                rec_result = whisperx.assign_word_speakers(diarize_segments, rec_result)
                logger.info("âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆ")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯´è¯äººåˆ†ç¦»æ‰§è¡Œå¤±è´¥: {str(e)}")
                logger.info("ğŸ‘‰ ç»§ç»­ä½¿ç”¨æ— è¯´è¯äººæ ‡è®°çš„ç»“æœ")
        else:
            logger.info("â„¹ï¸ æœªå¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼Œä½¿ç”¨å•è§’è‰²æ¨¡å¼")
        
    transcript = [{'start': segement['start'], 'end': segement['end'], 'text': segement['text'].strip(), 'speaker': segement.get('speaker', 'SPEAKER_00')} for segement in rec_result['segments']]
    return transcript


if __name__ == '__main__':
    for root, dirs, files in os.walk("videos"):
        if 'audio_vocals.wav' in files:
            logger.info(f'Transcribing {os.path.join(root, "audio_vocals.wav")}')
            transcript = whisperx_transcribe_audio(os.path.join(root, "audio_vocals.wav"))
            print(transcript)
            break