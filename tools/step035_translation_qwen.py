# -*- coding: utf-8 -*-
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
from loguru import logger

extra_body = {
    'repetition_penalty': 1.1,
}

def get_llm_api_config():
    """
    é€šç”¨çš„å¤§æ¨¡å‹APIé…ç½®åŠ è½½å‡½æ•°
    ä¼˜å…ˆè¯»å– cinecast é¡¹ç›®ä¸­çš„LLMé…ç½®ï¼Œæ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†
    """
    # å‡è®¾ videolanguage å’Œ cinecast åœ¨åŒä¸€ä¸ªçˆ¶ç›®å½•ä¸‹
    # ä¾‹å¦‚ï¼š
    # /workspace/cinecast/
    # /workspace/videolanguage/
    
    # 1. é¦–å…ˆæ£€æŸ¥æ–°çš„LLMé…ç½®æ–‡ä»¶ï¼ˆWebUIå¯èƒ½ä¿®æ”¹çš„ï¼‰
    cinecast_llm_config_path = os.path.abspath(
        os.path.join(os.path.dirname(__file__), "../../cinecast/.cinecast_llm_config.json")
    )
    if os.path.exists(cinecast_llm_config_path):
        try:
            with open(cinecast_llm_config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                logger.info(f"âœ… ä» cinecast LLM é…ç½®æ–‡ä»¶åŠ è½½: {cinecast_llm_config_path}")
                logger.info(f"ğŸ” é…ç½®å†…å®¹: {config}")
                return (
                    config.get("api_key", ""),
                    config.get("base_url", "https://api.openai.com/v1"),
                    config.get("model_name", "gpt-3.5-turbo")
                )
        except Exception as e:
            logger.warning(f"âš ï¸ è¯»å– cinecast LLM é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    # 2. å›é€€åˆ°åŠ è½½cinecastçš„.envæ–‡ä»¶
    cinecast_env_path = os.path.abspath(
        os.path.join(os.path.dirname(__file__), "../../cinecast/.env")
    )
    if os.path.exists(cinecast_env_path):
        load_dotenv(cinecast_env_path)
        logger.info(f"âœ… å·²åŠ è½½ cinecast .env æ–‡ä»¶: {cinecast_env_path}")
    
    # 3. æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("LLM_API_KEY")
    if api_key:
        logger.info(f"âœ… ä»ç¯å¢ƒå˜é‡è·å– API Key: {api_key[:10]}...")
        # æ ¹æ®APIå¯†é’¥å‰ç¼€åˆ¤æ–­æä¾›å•†
        if api_key.startswith("sk-5bc8c199"):
            # DeepSeek
            return api_key, "https://api.deepseek.com/v1", "deepseek-chat"
        else:
            # é»˜è®¤Qwen
            return api_key, "https://dashscope.aliyuncs.com/compatible-mode/v1", "qwen3.5-plus"
    
    # 4. æœ€åå›é€€åˆ°æ—§çš„é…ç½®æ–‡ä»¶
    cinecast_config_path = os.path.abspath(
        os.path.join(os.path.dirname(__file__), "../../cinecast/qwen_api_config.json")
    )
    
    logger.info(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ï¼Œå°è¯•è¯»å–æ—§é…ç½®æ–‡ä»¶")
    logger.info(f"ğŸ” æ­£åœ¨è¯»å–é…ç½®æ–‡ä»¶: {cinecast_config_path}")
    logger.info(f"ğŸ” æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(cinecast_config_path)}")
    
    api_key = None
    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    model_name = "qwen3.5-plus"

    if os.path.exists(cinecast_config_path):
        try:
            with open(cinecast_config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                logger.info(f"ğŸ” æ—§é…ç½®æ–‡ä»¶å†…å®¹: {config}")
                api_key = config.get("api_key", config.get("QWEN_API_KEY", ""))
                model_name = config.get("model", model_name)
                if "base_url" in config:
                    base_url = config["base_url"]
            logger.info(f"âœ… æˆåŠŸåŠ è½½æ—§ Cinecast é…ç½®æ–‡ä»¶: {cinecast_config_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ è¯»å–æ—§ Cinecast é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            
    # å¦‚æœéƒ½æ²¡è¯»åˆ°ï¼Œå°è¯•ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è·å–
    if not api_key:
        api_key = os.getenv("QWEN_API_KEY") or os.getenv("DASHSCOPE_API_KEY")
        
    if not api_key:
        raise ValueError("âŒ æ— æ³•æ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥ cinecast é…ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡")
        
    return api_key, base_url, model_name

def llm_response(messages):
    api_key, base_url, model_name = get_llm_api_config()
    
    client = OpenAI(
        base_url=base_url,
        api_key=api_key
    )
    response = client.chat.completions.create(
        model=model_name,
        messages=messages,
        timeout=240,
        extra_body=extra_body
    )
    return response.choices[0].message.content

if __name__ == '__main__':
    test_message = [{"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}]
    response = llm_response(test_message)
    print(response)